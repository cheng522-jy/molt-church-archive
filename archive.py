#!/usr/bin/env python3
"""
Molt Church å­˜æ¡£å·¥å…·
è‡ªåŠ¨æŠ“å– molt.church å…¨ç«™æ•°æ®å¹¶ä¿å­˜ä¸ºæœ¬åœ°å­˜æ¡£
æ”¯æŒå¢é‡æ›´æ–°
"""

import json
import os
import time
import hashlib
from datetime import datetime
from urllib.request import urlopen, Request
from urllib.error import URLError

# é…ç½®
BASE_URL = "https://molt.church"
ARCHIVE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(ARCHIVE_DIR, "data")
HTML_DIR = os.path.join(ARCHIVE_DIR, "html")
LOG_FILE = os.path.join(ARCHIVE_DIR, "sync_log.json")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(HTML_DIR, exist_ok=True)


def fetch_json(url):
    """è·å– JSON æ•°æ®"""
    try:
        req = Request(url, headers={"User-Agent": "MoltChurchArchiver/1.0"})
        with urlopen(req, timeout=30) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except Exception as e:
        print(f"  âŒ è·å–å¤±è´¥ {url}: {e}")
        return None


def fetch_html(url):
    """è·å– HTML å†…å®¹"""
    try:
        req = Request(url, headers={"User-Agent": "MoltChurchArchiver/1.0"})
        with urlopen(req, timeout=30) as resp:
            return resp.read().decode("utf-8")
    except Exception as e:
        print(f"  âŒ è·å–å¤±è´¥ {url}: {e}")
        return None


def save_json(data, filename):
    """ä¿å­˜ JSON æ•°æ®"""
    filepath = os.path.join(DATA_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"  âœ… å·²ä¿å­˜: {filename}")
    return filepath


def save_html(content, filename):
    """ä¿å­˜ HTML å†…å®¹"""
    filepath = os.path.join(HTML_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"  âœ… å·²ä¿å­˜: {filename}")
    return filepath


def load_log():
    """åŠ è½½åŒæ­¥æ—¥å¿—"""
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r") as f:
            return json.load(f)
    return {"syncs": [], "last_sync": None}


def save_log(log):
    """ä¿å­˜åŒæ­¥æ—¥å¿—"""
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(log, f, ensure_ascii=False, indent=2)


def archive_status():
    """å­˜æ¡£ç½‘ç«™çŠ¶æ€"""
    print("\nğŸ“Š è·å–ç½‘ç«™çŠ¶æ€...")
    data = fetch_json(f"{BASE_URL}/api/status")
    if data:
        save_json(data, "status.json")
        # ä¿å­˜å†å²å¿«ç…§
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_json(data, f"status_{timestamp}.json")
    return data


def archive_prophets():
    """å­˜æ¡£å…ˆçŸ¥åˆ—è¡¨"""
    print("\nğŸ¦€ è·å–å…ˆçŸ¥åˆ—è¡¨...")
    data = fetch_json(f"{BASE_URL}/api/prophets")
    if data:
        save_json(data, "prophets.json")
        print(f"  ğŸ“‹ å…± {len(data.get('prophets', []))} ä½å…ˆçŸ¥")
    return data


def archive_blessed():
    """å­˜æ¡£å—ç¥ç¦è€…åˆ—è¡¨"""
    print("\nâœ¨ è·å–å—ç¥ç¦è€…åˆ—è¡¨...")
    data = fetch_json(f"{BASE_URL}/api/blessed")
    if data:
        save_json(data, "blessed.json")
    return data


def archive_canon():
    """å­˜æ¡£å…¨éƒ¨ç»æ–‡ï¼ˆåˆ†é¡µè·å–ï¼‰"""
    print("\nğŸ“– è·å–ç»æ–‡ï¼ˆGreat Bookï¼‰...")
    all_verses = []
    page = 1
    per_page = 50

    while True:
        data = fetch_json(f"{BASE_URL}/api/canon?page={page}&per_page={per_page}")
        if not data or not data.get("the_great_book"):
            break

        verses = data["the_great_book"]
        all_verses.extend(verses)
        print(f"  ğŸ“œ ç¬¬ {page} é¡µ: {len(verses)} æ¡ç»æ–‡")

        if len(verses) < per_page:
            break
        page += 1
        time.sleep(0.5)  # ç¤¼è²Œè¯·æ±‚

    if all_verses:
        save_json({
            "success": True,
            "total": len(all_verses),
            "the_great_book": all_verses
        }, "canon_full.json")
        print(f"  ğŸ“š å…± {len(all_verses)} æ¡ç»æ–‡")

    return all_verses


def archive_html_pages():
    """å­˜æ¡£ HTML é¡µé¢"""
    print("\nğŸŒ è·å– HTML é¡µé¢...")

    pages = {
        "index.html": f"{BASE_URL}/",
        "gallery.html": f"{BASE_URL}/gallery.html",
    }

    for filename, url in pages.items():
        content = fetch_html(url)
        if content:
            save_html(content, filename)


def generate_summary(status, prophets, verses):
    """ç”Ÿæˆå­˜æ¡£æ‘˜è¦"""
    print("\nğŸ“ ç”Ÿæˆå­˜æ¡£æ‘˜è¦...")

    summary = f"""# Molt Church å­˜æ¡£æ‘˜è¦
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ç½‘ç«™çŠ¶æ€
- å…ˆçŸ¥æ•°é‡: {status.get('prophets_filled', 'N/A')}/64
- å—ç¥ç¦è€…: {status.get('blessed_count', 'N/A')}
- ä¼šä¼—è§„æ¨¡: {status.get('congregation_size', 'N/A')}
- ç»æ–‡æ€»æ•°: {status.get('canon_size', 'N/A')}

## 64 ä½å…ˆçŸ¥
"""
    if prophets:
        for p in prophets.get("prophets", []):
            summary += f"{p['prophet_number']}. **{p['name']}** - åŠ å…¥äº {p['joined_at'][:10]}\n"

    summary += f"\n## ç»æ–‡ç»Ÿè®¡\n"
    if verses:
        # æŒ‰ç±»å‹ç»Ÿè®¡
        types = {}
        for v in verses:
            t = v.get("scripture_type", "unknown")
            types[t] = types.get(t, 0) + 1

        for t, count in sorted(types.items(), key=lambda x: -x[1]):
            summary += f"- {t}: {count} æ¡\n"

        # æŒ‰ä½œè€…ç»Ÿè®¡
        authors = {}
        for v in verses:
            a = v.get("prophet_name", "unknown")
            authors[a] = authors.get(a, 0) + 1

        summary += f"\n## ç»æ–‡ä½œè€…æ’è¡Œï¼ˆå‰ 10ï¼‰\n"
        for a, count in sorted(authors.items(), key=lambda x: -x[1])[:10]:
            summary += f"- {a}: {count} æ¡\n"

    filepath = os.path.join(ARCHIVE_DIR, "SUMMARY.md")
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(summary)
    print(f"  âœ… å·²ä¿å­˜: SUMMARY.md")

    return summary


def run_archive():
    """æ‰§è¡Œå®Œæ•´å­˜æ¡£"""
    print("=" * 60)
    print("ğŸ¦€ Molt Church å­˜æ¡£å·¥å…·")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    log = load_log()

    # å­˜æ¡£å„éƒ¨åˆ†
    status = archive_status()
    prophets = archive_prophets()
    blessed = archive_blessed()
    verses = archive_canon()
    archive_html_pages()

    # ç”Ÿæˆæ‘˜è¦
    if status:
        generate_summary(status, prophets, verses)

    # æ›´æ–°æ—¥å¿—
    sync_record = {
        "time": datetime.now().isoformat(),
        "status": {
            "prophets": status.get("prophets_filled", 0) if status else 0,
            "congregation": status.get("congregation_size", 0) if status else 0,
            "canon": status.get("canon_size", 0) if status else 0,
        }
    }
    log["syncs"].append(sync_record)
    log["last_sync"] = sync_record["time"]
    save_log(log)

    print("\n" + "=" * 60)
    print("âœ… å­˜æ¡£å®Œæˆï¼")
    print(f"ğŸ“ å­˜æ¡£ç›®å½•: {ARCHIVE_DIR}")
    print("=" * 60)


if __name__ == "__main__":
    run_archive()
